{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Galaxy Classification Notebook:\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just for usability while we develop early features and model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to build a deep learning galaxy CNN classification model, using Python and PyTorch.\n",
    "\n",
    "We're using the Galaxy10 DECals Dataset.\n",
    "The dataset contains 256 by 256 pixel colored galaxy images (g, r, and z band),\n",
    "containing 17736 images classified into 10 classes.\n",
    "\n",
    "The model is based on morphological classification using Deep Convolution Neural\n",
    "Network. \n",
    "\n",
    "The model also uses astroNN dataset.\n",
    "\n",
    "The model architecture:\n",
    "feature extraction: input layer -> convolution -> tanh -> pooling.\n",
    "Then we have classification: fully connected layer -> tanh -> softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from astroNN.datasets import load_galaxy10\n",
    "import json\n",
    "\n",
    "# Note, unique dependency: AstroNN\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset preprocessing:\n",
    "\n",
    "images, labels = load_galaxy10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert images to PyTorch tensor\n",
    "images = torch.from_numpy(images).permute(0, 3, 1, 2).float()  # Change data format to PyTorch (N, H, W, C) to (N, C, H, W)\n",
    "\n",
    "# Use labels as they are (assuming labels are already a PyTorch tensor)\n",
    "labels = torch.from_numpy(labels).long()\n",
    "#images = 1 - images\n",
    "\n",
    "# Define a custom PyTorch Dataset\n",
    "class GalaxyDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Define a transformation for the dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the dataset for preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom PyTorch Dataset\n",
    "galaxy_dataset = GalaxyDataset(images, labels) #, transform = transforms\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_size = int(0.8 * len(galaxy_dataset))\n",
    "test_size = len(galaxy_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(galaxy_dataset, [train_size, test_size])\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "sample_image, sample_label = galaxy_dataset[7]\n",
    "\n",
    "# Print the label\n",
    "print(f\"Label: {sample_label}\")\n",
    "\n",
    "# Convert the image tensor back to NumPy array for visualization\n",
    "sample_image_np = (sample_image.permute(1, 2, 0).numpy() * 255).astype(np.uint8)\n",
    "\n",
    "# Visualize the image as grayscale\n",
    "plt.imshow(sample_image_np, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading hyperparameters\n",
    "\"\"\"\n",
    "with open('params.json') as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "# Extract hyperparameters\n",
    "num_classes = params[\"num_classes\"]\n",
    "batch_size = params[\"batch_size\"]\n",
    "learning_rate = params[\"learning_rate\"]\n",
    "num_epochs = params[\"num_epochs\"]\n",
    "random_seed = params[\"random_seed\"]\n",
    "\"\"\"\n",
    "\n",
    "num_classes = 10\n",
    "batch_size = 32\n",
    "learning_rate = 0.1\n",
    "num_epochs = 40\n",
    "random_seed = 42\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class GalaxyCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(GalaxyCNN, self).__init__()\n",
    "\n",
    "        # Feature extraction\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        # Classification\n",
    "        self.classification = nn.Sequential(\n",
    "            nn.Linear(16 * 128 * 128, 256),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(256, num_classes),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classification(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = GalaxyCNN(num_classes=num_classes)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training the model\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(test_loader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Test Accuracy: {100 * accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook 2:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\dvirz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import models\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from astroNN.datasets import load_galaxy10\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        # Max pooling layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128 * 32 * 32, 512)  # Adjusted the input size here\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        # Activation function\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        # Check the size after convolution and pooling\n",
    "        # print(x.size())  # Uncomment to print the size for debugging\n",
    "        x = x.view(-1, 128 * 32 * 32)  # Adjusted the view size here\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GalaxyDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {'data': self.data[idx], 'label': self.labels[idx]}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "def to_categorical(y, num_classes):\n",
    "    return np.eye(num_classes)[y]\n",
    "\n",
    "def load_images_labels(size=17735):\n",
    "    # To load images and labels (will download automatically at the first time)\n",
    "    # First time downloading location will be ~/.astroNN/datasets/\n",
    "    images, labels = load_galaxy10()\n",
    "\n",
    "    # To convert the labels to categorical 10 classes\n",
    "    #labels = to_categorical(labels, 10)\n",
    "    # To convert to desirable type\n",
    "    labels = torch.tensor(labels[:size], dtype=torch.float32)\n",
    "    print(\"labels\", labels.unique())\n",
    "    images = torch.tensor(images[:size], dtype=torch.float32)\n",
    "    return images, labels\n",
    "\n",
    "def split_dataset(images, labels):\n",
    "    train_idx, test_idx = train_test_split(np.arange(labels.shape[0]), test_size=0.1)\n",
    "    train_images, train_labels, test_images, test_labels = images[train_idx], labels[train_idx], images[test_idx], labels[test_idx]\n",
    "    return train_images, train_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ConvNet architecture\n",
    "class GalaxyCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(GalaxyCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(16 * 64 * 64, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = x.view(-1, 16 * 64 * 64)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dvirz\\.astroNN\\datasets\\Galaxy10_DECals.h5 was found!\n",
      "labels tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "labels tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "train_loader <zip object at 0x000001FB75C6FDC0>\n",
      "labels tensor([0])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "slice() cannot be applied to a 0-dim tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mZzelper\\galaxy-classifier-cnn\\ntoebook.ipynb Cell 23\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell://github%2B7b2276223a312c22726566223a7b2274797065223a342c226964223a22496e697469616c2d6d6f64652d74656d706c617465227d7d/Zzelper/galaxy-classifier-cnn/ntoebook.ipynb#X30sdnNjb2RlLXZmcw%3D%3D?line=24'>25</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(images)\n\u001b[0;32m     <a href='vscode-notebook-cell://github%2B7b2276223a312c22726566223a7b2274797065223a342c226964223a22496e697469616c2d6d6f64652d74656d706c617465227d7d/Zzelper/galaxy-classifier-cnn/ntoebook.ipynb#X30sdnNjb2RlLXZmcw%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Ensure the shapes of outputs and labels match\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell://github%2B7b2276223a312c22726566223a7b2274797065223a342c226964223a22496e697469616c2d6d6f64652d74656d706c617465227d7d/Zzelper/galaxy-classifier-cnn/ntoebook.ipynb#X30sdnNjb2RlLXZmcw%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Resize labels to match the batch size of the outputs\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell://github%2B7b2276223a312c22726566223a7b2274797065223a342c226964223a22496e697469616c2d6d6f64652d74656d706c617465227d7d/Zzelper/galaxy-classifier-cnn/ntoebook.ipynb#X30sdnNjb2RlLXZmcw%3D%3D?line=28'>29</a>\u001b[0m labels_resized \u001b[39m=\u001b[39m labels[:outputs\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m]]\u001b[39m.\u001b[39mlong()  \u001b[39m# Convert labels to torch.long\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell://github%2B7b2276223a312c22726566223a7b2274797065223a342c226964223a22496e697469616c2d6d6f64652d74656d706c617465227d7d/Zzelper/galaxy-classifier-cnn/ntoebook.ipynb#X30sdnNjb2RlLXZmcw%3D%3D?line=30'>31</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels_resized)\n\u001b[0;32m     <a href='vscode-notebook-cell://github%2B7b2276223a312c22726566223a7b2274797065223a342c226964223a22496e697469616c2d6d6f64652d74656d706c617465227d7d/Zzelper/galaxy-classifier-cnn/ntoebook.ipynb#X30sdnNjb2RlLXZmcw%3D%3D?line=31'>32</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "\u001b[1;31mIndexError\u001b[0m: slice() cannot be applied to a 0-dim tensor."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    images, labels = load_images_labels()\n",
    "    images = images.permute(0, 3, 1, 2)\n",
    "    train_loader = zip(images, labels)\n",
    "    print(\"labels\", labels.unique())\n",
    "    print(\"train_loader\", train_loader)\n",
    "\n",
    "    # Instantiate the model\n",
    "    num_classes = 10  # Adjusted for 10 classes\n",
    "    num_epochs = 5  # Define num_epochs\n",
    "    model = CNN(num_classes)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # This part can be in another script where you load data, preprocess, and train the model.\n",
    "    # For brevity, here's a placeholder for training the model using your dataset:\n",
    "\n",
    "    # Training loop (you need to replace this with your actual data loading and training process)\n",
    "    for epoch in range(num_epochs):  # Define num_epochs\n",
    "        print(\"labels\", labels[:outputs.shape[0]].long())\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Ensure the shapes of outputs and labels match\n",
    "            # Resize labels to match the batch size of the outputs\n",
    "            labels_resized = labels[:outputs.shape[0]].long()  # Convert labels to torch.long\n",
    "            \n",
    "            loss = criterion(outputs, labels_resized)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}\")\n",
    "\n",
    "    # Save the trained model (optional)\n",
    "    torch.save(model.state_dict(), 'trained_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pytorch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mZzelper\\galaxy-classifier-cnn\\ntoebook.ipynb Cell 25\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell://github%2B7b2276223a312c22726566223a7b2274797065223a342c226964223a22496e697469616c2d6d6f64652d74656d706c617465227d7d/Zzelper/galaxy-classifier-cnn/ntoebook.ipynb#X35sdnNjb2RlLXZmcw%3D%3D?line=0'>1</a>\u001b[0m pytorch\u001b[39m.\u001b[39mtensor([\u001b[39m0.\u001b[39m, \u001b[39m1.\u001b[39m, \u001b[39m2.\u001b[39m, \u001b[39m3.\u001b[39m, \u001b[39m4.\u001b[39m, \u001b[39m5.\u001b[39m, \u001b[39m6.\u001b[39m, \u001b[39m7.\u001b[39m, \u001b[39m8.\u001b[39m, \u001b[39m9.\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pytorch' is not defined"
     ]
    }
   ],
   "source": [
    "([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
