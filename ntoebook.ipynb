{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Galaxy Classification Notebook:\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just for usability while we develop early features and model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to build a deep learning galaxy CNN classification model, using Python and PyTorch.\n",
    "\n",
    "We're using the Galaxy10 DECals Dataset.\n",
    "The dataset contains 256 by 256 pixel colored galaxy images (g, r, and z band),\n",
    "containing 17736 images classified into 10 classes.\n",
    "\n",
    "The model is based on morphological classification using Deep Convolution Neural\n",
    "Network. \n",
    "\n",
    "The model also uses astroNN dataset.\n",
    "\n",
    "The model architecture:\n",
    "feature extraction: input layer -> convolution -> tanh -> pooling.\n",
    "Then we have classification: fully connected layer -> tanh -> softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\dvirz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from astroNN.datasets import load_galaxy10\n",
    "import json\n",
    "\n",
    "# Note, unique dependency: AstroNN\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dvirz\\.astroNN\\datasets\\Galaxy10_DECals.h5 was found!\n"
     ]
    }
   ],
   "source": [
    "## Dataset preprocessing:\n",
    "\n",
    "images, labels = load_galaxy10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert images to PyTorch tensor\n",
    "images = torch.from_numpy(images).permute(0, 3, 1, 2).float()  # Change data format to PyTorch (N, H, W, C) to (N, C, H, W)\n",
    "\n",
    "# Use labels as they are (assuming labels are already a PyTorch tensor)\n",
    "labels = torch.from_numpy(labels).long()\n",
    "#images = 1 - images\n",
    "\n",
    "# Define a custom PyTorch Dataset\n",
    "class GalaxyDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Define a transformation for the dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the dataset for preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom PyTorch Dataset\n",
    "galaxy_dataset = GalaxyDataset(images, labels) #, transform = transforms\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_size = int(0.8 * len(galaxy_dataset))\n",
    "test_size = len(galaxy_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(galaxy_dataset, [train_size, test_size])\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "sample_image, sample_label = galaxy_dataset[7]\n",
    "\n",
    "# Print the label\n",
    "print(f\"Label: {sample_label}\")\n",
    "\n",
    "# Convert the image tensor back to NumPy array for visualization\n",
    "sample_image_np = (sample_image.permute(1, 2, 0).numpy() * 255).astype(np.uint8)\n",
    "\n",
    "# Visualize the image as grayscale\n",
    "plt.imshow(sample_image_np, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x23cb417f9f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading hyperparameters\n",
    "\"\"\"\n",
    "with open('params.json') as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "# Extract hyperparameters\n",
    "num_classes = params[\"num_classes\"]\n",
    "batch_size = params[\"batch_size\"]\n",
    "learning_rate = params[\"learning_rate\"]\n",
    "num_epochs = params[\"num_epochs\"]\n",
    "random_seed = params[\"random_seed\"]\n",
    "\"\"\"\n",
    "\n",
    "num_classes = 10\n",
    "batch_size = 32\n",
    "learning_rate = 0.1\n",
    "num_epochs = 40\n",
    "random_seed = 42\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class GalaxyCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(GalaxyCNN, self).__init__()\n",
    "\n",
    "        # Feature extraction\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        # Classification\n",
    "        self.classification = nn.Sequential(\n",
    "            nn.Linear(16 * 128 * 128, 256),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(256, num_classes),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classification(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Galaxy10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "galaxy_dataset = GalaxyDataset(images, labels, transform=transform)\n",
    "train_size = int(0.8 * len(galaxy_dataset))\n",
    "test_size = len(galaxy_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(galaxy_dataset, [train_size, test_size])\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mZzelper\\galaxy-classifier-cnn\\ntoebook.ipynb Cell 14\u001b[0m line \u001b[0;36m<cell line: 55>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell://github%2B7b2276223a312c22726566223a7b2274797065223a342c226964223a22496e697469616c2d6d6f64652d74656d706c617465227d7d/Zzelper/galaxy-classifier-cnn/ntoebook.ipynb#X15sdnNjb2RlLXZmcw%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m     <a href='vscode-notebook-cell://github%2B7b2276223a312c22726566223a7b2274797065223a342c226964223a22496e697469616c2d6d6f64652d74656d706c617465227d7d/Zzelper/galaxy-classifier-cnn/ntoebook.ipynb#X15sdnNjb2RlLXZmcw%3D%3D?line=55'>56</a>\u001b[0m     model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m---> <a href='vscode-notebook-cell://github%2B7b2276223a312c22726566223a7b2274797065223a342c226964223a22496e697469616c2d6d6f64652d74656d706c617465227d7d/Zzelper/galaxy-classifier-cnn/ntoebook.ipynb#X15sdnNjb2RlLXZmcw%3D%3D?line=56'>57</a>\u001b[0m     \u001b[39mfor\u001b[39;00m inputs, labels \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     <a href='vscode-notebook-cell://github%2B7b2276223a312c22726566223a7b2274797065223a342c226964223a22496e697469616c2d6d6f64652d74656d706c617465227d7d/Zzelper/galaxy-classifier-cnn/ntoebook.ipynb#X15sdnNjb2RlLXZmcw%3D%3D?line=57'>58</a>\u001b[0m         optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell://github%2B7b2276223a312c22726566223a7b2274797065223a342c226964223a22496e697469616c2d6d6f64652d74656d706c617465227d7d/Zzelper/galaxy-classifier-cnn/ntoebook.ipynb#X15sdnNjb2RlLXZmcw%3D%3D?line=58'>59</a>\u001b[0m         outputs \u001b[39m=\u001b[39m model(inputs)\n",
      "File \u001b[1;32mc:\\Users\\dvirz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\dvirz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\dvirz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset, \u001b[39m\"\u001b[39m\u001b[39m__getitems__\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\dvirz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataset.py:364\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices])  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 364\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[idx]] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices]\n",
      "File \u001b[1;32mc:\\Users\\dvirz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataset.py:364\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices])  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 364\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices]\n",
      "\u001b[1;32mZzelper\\galaxy-classifier-cnn\\ntoebook.ipynb Cell 14\u001b[0m line \u001b[0;36mGalaxyDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell://github%2B7b2276223a312c22726566223a7b2274797065223a342c226964223a22496e697469616c2d6d6f64652d74656d706c617465227d7d/Zzelper/galaxy-classifier-cnn/ntoebook.ipynb#X15sdnNjb2RlLXZmcw%3D%3D?line=12'>13</a>\u001b[0m label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels[idx]\n\u001b[0;32m     <a href='vscode-notebook-cell://github%2B7b2276223a312c22726566223a7b2274797065223a342c226964223a22496e697469616c2d6d6f64652d74656d706c617465227d7d/Zzelper/galaxy-classifier-cnn/ntoebook.ipynb#X15sdnNjb2RlLXZmcw%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform:\n\u001b[1;32m---> <a href='vscode-notebook-cell://github%2B7b2276223a312c22726566223a7b2274797065223a342c226964223a22496e697469616c2d6d6f64652d74656d706c617465227d7d/Zzelper/galaxy-classifier-cnn/ntoebook.ipynb#X15sdnNjb2RlLXZmcw%3D%3D?line=15'>16</a>\u001b[0m     image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(image)\n\u001b[0;32m     <a href='vscode-notebook-cell://github%2B7b2276223a312c22726566223a7b2274797065223a342c226964223a22496e697469616c2d6d6f64652d74656d706c617465227d7d/Zzelper/galaxy-classifier-cnn/ntoebook.ipynb#X15sdnNjb2RlLXZmcw%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mreturn\u001b[39;00m image, label\n",
      "File \u001b[1;32mc:\\Users\\dvirz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\dvirz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[1;32mc:\\Users\\dvirz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\functional.py:140\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    138\u001b[0m     _log_api_usage_once(to_tensor)\n\u001b[0;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (F_pil\u001b[39m.\u001b[39m_is_pil_image(pic) \u001b[39mor\u001b[39;00m _is_numpy(pic)):\n\u001b[1;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpic should be PIL Image or ndarray. Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(pic)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    142\u001b[0m \u001b[39mif\u001b[39;00m _is_numpy(pic) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_numpy_image(pic):\n\u001b[0;32m    143\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpic should be 2/3 dimensional. Got \u001b[39m\u001b[39m{\u001b[39;00mpic\u001b[39m.\u001b[39mndim\u001b[39m}\u001b[39;00m\u001b[39m dimensions.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Assuming you have already loaded and preprocessed your data into PyTorch tensors\n",
    "# x_train, y_train, x_val, y_val are your training and validation sets\n",
    "# Define your CNN model\n",
    "class GalaxyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GalaxyCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64 * 128 * 128, 256),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(256, 10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output for the fully connected layer\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = GalaxyCNN()\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Convert your data to PyTorch Dataset and DataLoader\n",
    "# Load the Galaxy10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "galaxy_dataset = GalaxyDataset(images, labels, transform=transform)\n",
    "train_size = int(0.8 * len(galaxy_dataset))\n",
    "test_size = len(galaxy_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(galaxy_dataset, [train_size, test_size])\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = correct / total\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Save the trained model if needed\n",
    "torch.save(model.state_dict(), 'galaxy_cnn_model.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
